@InProceedings{Pan2022,
  author    = {Pan, Li and Wang, Lin and Chen, Shutong and Liu, Fangming},
  booktitle = {IEEE INFOCOM 2022 - IEEE Conference on Computer Communications},
  title     = {Retention-Aware Container Caching for Serverless Edge Computing},
  year      = {2022},
  pages     = {1069-1078},
  doi       = {10.1109/INFOCOM48880.2022.9796705},
}

@InProceedings{Fuerst2021,
  author    = {Fuerst, Alexander and Sharma, Prateek},
  title     = {FaasCache: Keeping Serverless Computing Alive with Greedy-Dual Caching},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {386–400},
  publisher = {Association for Computing Machinery},
  series    = {ASPLOS '21},
  doi       = {10.1145/3445814.3446757},
  isbn      = {9781450383172},
  keywords  = {Caching, Functions as a Service, Cloud Computing, Serverless Computing},
  location  = {Virtual, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3445814.3446757},
}

@InProceedings{Mittal2021,
  author    = {Mittal, Viyom and Qi, Shixiong and Bhattacharya, Ratnadeep and Lyu, Xiaosu and Li, Junfeng and Kulkarni, Sameer G. and Li, Dan and Hwang, Jinho and Ramakrishnan, K. K. and Wood, Timothy},
  booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
  title     = {Mu: An Efficient, Fair and Responsive Serverless Framework for Resource-Constrained Edge Clouds},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {168–181},
  publisher = {Association for Computing Machinery},
  series    = {SoCC '21},
  doi       = {10.1145/3472883.3487014},
  isbn      = {9781450386388},
  keywords  = {Edge clouds, serverless, resource management},
  location  = {Seattle, WA, USA},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3472883.3487014},
}

@Article{Lin2023,
  author  = {Lin, Changyuan and Mahmoudi, Nima and Fan, Caixiang and Khazaei, Hamzeh},
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  title   = {Fine-Grained Performance and Cost Modeling and Optimization for FaaS Applications},
  year    = {2023},
  number  = {1},
  pages   = {180-194},
  volume  = {34},
  doi     = {10.1109/TPDS.2022.3214783},
}

@InProceedings{Shahrad2020,
  author    = {Shahrad, Mohammad and Fonseca, Rodrigo and Goiri, \'{I}\~{n}igo and Chaudhry, Gohar and Batum, Paul and Cooke, Jason and Laureano, Eduardo and Tresness, Colby and Russinovich, Mark and Bianchini, Ricardo},
  booktitle = {Proceedings of the 2020 USENIX Conference on Usenix Annual Technical Conference},
  title     = {Serverless in the Wild: Characterizing and Optimizing the Serverless Workload at a Large Cloud Provider},
  year      = {2020},
  address   = {USA},
  publisher = {USENIX Association},
  series    = {USENIX ATC'20},
  articleno = {14},
  isbn      = {978-1-939133-14-4},
  numpages  = {14},
}

@InProceedings{Roy2022,
  author    = {Roy, Rohan Basu and Patel, Tirthak and Tiwari, Devesh},
  booktitle = {Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
  title     = {IceBreaker: Warming Serverless Functions Better with Heterogeneity},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {753–767},
  publisher = {Association for Computing Machinery},
  series    = {ASPLOS '22},
  doi       = {10.1145/3503222.3507750},
  isbn      = {9781450392051},
  keywords  = {Serverless Computing, Cold Start, Heterogeneous Hardware, Cloud Computing, Keep-alive Cost},
  location  = {Lausanne, Switzerland},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3503222.3507750},
}

@InProceedings{Mvondo2021,
  author    = {Mvondo, Djob and Bacou, Mathieu and Nguetchouang, Kevin and Ngale, Lucien and Pouget, St\'{e}phane and Kouam, Josiane and Lachaize, Renaud and Hwang, Jinho and Wood, Tim and Hagimont, Daniel and De Palma, No\"{e}l and Batchakui, Bernab\'{e} and Tchana, Alain},
  title     = {OFC: An Opportunistic Caching System for FaaS Platforms},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {228–244},
  publisher = {Association for Computing Machinery},
  series    = {EuroSys '21},
  doi       = {10.1145/3447786.3456239},
  isbn      = {9781450383349},
  keywords  = {latency, functions as a service (FaaS), cache, cloud computing, serverless},
  location  = {Online Event, United Kingdom},
  numpages  = {17},
  url       = {https://doi.org/10.1145/3447786.3456239},
}

@InProceedings{Lai2018,
  author    = {Lai, Phu and He, Qiang and Abdelrazek, Mohamed and Chen, Feifei and Hosking, John and Grundy, John and Yang, Yun},
  booktitle = {Service-Oriented Computing},
  title     = {Optimal Edge User Allocation in Edge Computing with Variable Sized Vector Bin Packing},
  year      = {2018},
  address   = {Cham},
  editor    = {Pahl, Claus and Vukovic, Maja and Yin, Jianwei and Yu, Qi},
  pages     = {230--245},
  publisher = {Springer International Publishing},
  isbn      = {978-3-030-03596-9},
}

@Misc{azure2019,
  author       = {Azure},
  howpublished = {\url{https://github.com/Azure/AzurePublicDataset/blob/master/AzureFunctionsDataset2019.md}},
  title        = {AzurePublicDataset},
  year         = {2019},
}

@InProceedings{Russo2023,
  author    = {Russo, Gabriele Russo and Mannucci, Tiziana and Cardellini, Valeria and Presti, Francesco Lo},
  booktitle = {2023 IEEE International Conference on Pervasive Computing and Communications (PerCom)},
  title     = {Serverledge: Decentralized Function-as-a-Service for the Edge-Cloud Continuum},
  year      = {2023},
  pages     = {131-140},
  doi       = {10.1109/PERCOM56429.2023.10099372},
}

@Article{Paraskevoulakou2023,
  author  = {Paraskevoulakou, Efterpi and Kyriazis, Dimosthenis},
  journal = {IEEE Transactions on Network and Service Management},
  title   = {ML-FaaS: Towards exploiting the serverless paradigm to facilitate Machine Learning Functions as a Service},
  year    = {2023},
  pages   = {1-1},
  doi     = {10.1109/TNSM.2023.3239672},
}

@InProceedings{Stojkovic2023,
  author    = {Stojkovic, Jovan and Xu, Tianyin and Franke, Hubertus and Torrellas, Josep},
  booktitle = {Proceedings of the 50th Annual International Symposium on Computer Architecture},
  title     = {MXFaaS: Resource Sharing in Serverless Environments for Parallelism and Efficiency},
  year      = {2023},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ISCA '23},
  articleno = {34},
  doi       = {10.1145/3579371.3589069},
  isbn      = {9798400700958},
  keywords  = {serverless computing, cloud computing, resource management},
  location  = {Orlando, FL, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3579371.3589069},
}

@Article{Lin2023a,
  author  = {Lin, Changyuan and Mahmoudi, Nima and Fan, Caixiang and Khazaei, Hamzeh},
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  title   = {Fine-Grained Performance and Cost Modeling and Optimization for FaaS Applications},
  year    = {2023},
  number  = {1},
  pages   = {180-194},
  volume  = {34},
  doi     = {10.1109/TPDS.2022.3214783},
}

@InProceedings{Zhou2022,
  author    = {Zhou, Ruiting and Wu, Xiaoyi and Tan, Haisheng and Zhang, Renli},
  booktitle = {IEEE INFOCOM 2022 - IEEE Conference on Computer Communications},
  title     = {Two Time-Scale Joint Service Caching and Task Offloading for UAV-assisted Mobile Edge Computing},
  year      = {2022},
  pages     = {1189-1198},
  doi       = {10.1109/INFOCOM48880.2022.9796714},
}

@InProceedings{Cao2018,
  author    = {Cao, Xuanyu and Zhang, Junshan and Poor, H. Vincent},
  booktitle = {2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS)},
  title     = {An Optimal Auction Mechanism for Mobile Edge Caching},
  year      = {2018},
  pages     = {388-399},
  doi       = {10.1109/ICDCS.2018.00046},
}

@Article{Chu1997,
  author  = {P.C. Chu and J.E. Beasley},
  journal = {Computers & Operations Research},
  title   = {A genetic algorithm for the generalised assignment problem},
  year    = {1997},
  issn    = {0305-0548},
  number  = {1},
  pages   = {17-23},
  volume  = {24},
  doi     = {https://doi.org/10.1016/S0305-0548(96)00032-9},
  url     = {https://www.sciencedirect.com/science/article/pii/S0305054896000329},
}

@Article{Li2023,
  author  = {Li, Yongkang and Lin, Yanying and Wang, Yang and Ye, Kejiang and Xu, Chengzhong},
  journal = {IEEE Transactions on Services Computing},
  title   = {Serverless Computing: State-of-the-Art, Challenges and Opportunities},
  year    = {2023},
  number  = {2},
  pages   = {1522-1539},
  volume  = {16},
  doi     = {10.1109/TSC.2022.3166553},
}

@Article{Li2022,
  author     = {Li, Zijun and Guo, Linsong and Cheng, Jiagan and Chen, Quan and He, Bingsheng and Guo, Minyi},
  journal    = {ACM Comput. Surv.},
  title      = {The Serverless Computing Survey: A Technical Primer for Design Architecture},
  year       = {2022},
  issn       = {0360-0300},
  month      = {sep},
  number     = {10s},
  volume     = {54},
  abstract   = {The development of cloud infrastructures inspires the emergence of cloud-native computing. As the most promising architecture for deploying microservices, serverless computing has recently attracted more and more attention in both industry and academia. Due to its inherent scalability and flexibility, serverless computing becomes attractive and more pervasive for ever-growing Internet services. Despite the momentum in the cloud-native community, the existing challenges and compromises still wait for more advanced research and solutions to further explore the potential of the serverless computing model. As a contribution to this knowledge, this article surveys and elaborates the research domains in the serverless context by decoupling the architecture into four stack layers: Virtualization, Encapsule, System Orchestration, and System Coordination. Inspired by the security model, we highlight the key implications and limitations of these works in each layer, and make suggestions for potential challenges to the field of future serverless computing.},
  address    = {New York, NY, USA},
  articleno  = {220},
  doi        = {10.1145/3508360},
  issue_date = {January 2022},
  keywords   = {Serverless computing, FaaS, Lambda paradigm, architecture design},
  numpages   = {34},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3508360},
}

@Article{Kounev2023,
  author     = {Kounev, Samuel and Herbst, Nikolas and Abad, Cristina L. and Iosup, Alexandru and Foster, Ian and Shenoy, Prashant and Rana, Omer and Chien, Andrew A.},
  journal    = {Commun. ACM},
  title      = {Serverless Computing: What It Is, and What It Is Not?},
  year       = {2023},
  issn       = {0001-0782},
  month      = {aug},
  number     = {9},
  pages      = {80–92},
  volume     = {66},
  abstract   = {Dispelling the confusion around serverless computing by capturing its essential and conceptual characteristics.},
  address    = {New York, NY, USA},
  doi        = {10.1145/3587249},
  issue_date = {September 2023},
  numpages   = {13},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3587249},
}

@Article{Li2022a,
  author     = {Li, Zijun and Guo, Linsong and Cheng, Jiagan and Chen, Quan and He, Bingsheng and Guo, Minyi},
  journal    = {ACM Comput. Surv.},
  title      = {The Serverless Computing Survey: A Technical Primer for Design Architecture},
  year       = {2022},
  issn       = {0360-0300},
  month      = {sep},
  number     = {10s},
  volume     = {54},
  abstract   = {The development of cloud infrastructures inspires the emergence of cloud-native computing. As the most promising architecture for deploying microservices, serverless computing has recently attracted more and more attention in both industry and academia. Due to its inherent scalability and flexibility, serverless computing becomes attractive and more pervasive for ever-growing Internet services. Despite the momentum in the cloud-native community, the existing challenges and compromises still wait for more advanced research and solutions to further explore the potential of the serverless computing model. As a contribution to this knowledge, this article surveys and elaborates the research domains in the serverless context by decoupling the architecture into four stack layers: Virtualization, Encapsule, System Orchestration, and System Coordination. Inspired by the security model, we highlight the key implications and limitations of these works in each layer, and make suggestions for potential challenges to the field of future serverless computing.},
  address    = {New York, NY, USA},
  articleno  = {220},
  doi        = {10.1145/3508360},
  issue_date = {January 2022},
  keywords   = {architecture design, Lambda paradigm, Serverless computing, FaaS},
  numpages   = {34},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3508360},
}

@InProceedings{Stojkovic2023a,
  author    = {Stojkovic, Jovan and Xu, Tianyin and Franke, Hubertus and Torrellas, Josep},
  booktitle = {Proceedings of the 50th Annual International Symposium on Computer Architecture},
  title     = {MXFaaS: Resource Sharing in Serverless Environments for Parallelism and Efficiency},
  year      = {2023},
  address   = {New York, NY, USA},
  publisher = {Association for Computing Machinery},
  series    = {ISCA '23},
  abstract  = {Although serverless computing is a popular paradigm, current serverless environments have high overheads. Recently, it has been shown that serverless workloads frequently exhibit bursts of invocations of the same function. Such pattern is not handled well in current platforms. Supporting it efficiently can speed-up serverless execution substantially.In this paper, we target this dominant pattern with a new server-less platform design named MXFaaS. MXFaaS improves function performance by efficiently multiplexing (i.e., sharing) processor cycles, I/O bandwidth, and memory/processor state between concurrently executing invocations of the same function. MXFaaS introduces a new container abstraction called MXContainer. To enable efficient use of processor cycles, an MXContainer carefully helps schedule same-function invocations for minimal response time. To enable efficient use of I/O bandwidth, an MXContainer coalesces remote storage accesses and remote function calls from same-function invocations. Finally, to enable efficient use of memory/processor state, an MXContainer first initializes the state of its container and only later, on demand, spawns a process per function invocation, so that all invocations can share unmodified memory state and hence minimize memory footprint.We implement MXFaaS in two serverless platforms and run diverse serverless benchmarks. With MXFaaS, serverless environments are much more efficient. Compared to a state-of-the-art serverless environment, MXFaaS on average speeds-up execution by 5.2\texttimes{}, reduces P99 tail latency by 7.4\texttimes{}, and improves throughput by 4.8\texttimes{}. In addition, it reduces the average memory usage by 3.4\texttimes{}.},
  articleno = {34},
  doi       = {10.1145/3579371.3589069},
  isbn      = {9798400700958},
  keywords  = {resource management, cloud computing, serverless computing},
  location  = {Orlando, FL, USA},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3579371.3589069},
}

@InProceedings{Yu2023,
  author    = {Minchen Yu and Tingjia Cao and Wei Wang and Ruichuan Chen},
  booktitle = {20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23)},
  title     = {Following the Data, Not the Function: Rethinking Function Orchestration in Serverless Computing},
  year      = {2023},
  address   = {Boston, MA},
  month     = apr,
  pages     = {1489--1504},
  publisher = {USENIX Association},
  isbn      = {978-1-939133-33-5},
  url       = {https://www.usenix.org/conference/nsdi23/presentation/yu},
}

@InProceedings{Schall2022,
  author    = {Schall, David and Margaritov, Artemiy and Ustiugov, Dmitrii and Sandberg, Andreas and Grot, Boris},
  booktitle = {Proceedings of the 49th Annual International Symposium on Computer Architecture},
  title     = {Lukewarm Serverless Functions: Characterization and Optimization},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {757–770},
  publisher = {Association for Computing Machinery},
  series    = {ISCA '22},
  abstract  = {Serverless computing has emerged as a widely-used paradigm for running services in the cloud. In serverless, developers organize their applications as a set of functions, which are invoked on-demand in response to events, such as an HTTP request. To avoid long start-up delays of launching a new function instance, cloud providers tend to keep recently-triggered instances idle (or warm) for some time after the most recent invocation in anticipation of future invocations. Thus, at any given moment on a server, there may be thousands of warm instances of various functions whose executions are interleaved in time based on incoming invocations.This paper observes that (1) there is a high degree of interleaving among warm instances on a given server; (2) the individual warm functions are invoked relatively infrequently, often at the granularity of seconds or minutes; and (3) many function invocations complete within a few milliseconds. Interleaved execution of rarely invoked functions on a server leads to thrashing of each function's microarchitectural state between invocations. Meanwhile, the short execution time of a function impedes amortization of the warm-up latency of the cache hierarchy, causing a 31--114\% increase in CPI compared to execution with warm microarchitectural state. We identify on-chip misses for instructions as a major contributor to the performance loss. In response we propose Jukebox, a record-and-replay instruction prefetcher specifically designed for reducing the start-up latency of warm function instances. Jukebox requires just 32KB of metadata per function instance and boosts performance by an average of 18.7\% for a wide range of functions, which translates into a corresponding throughput improvement.},
  doi       = {10.1145/3470496.3527390},
  isbn      = {9781450386104},
  keywords  = {serverless, instruction prefetching, characterization, microarchitecture},
  location  = {New York, New York},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3470496.3527390},
}

@InProceedings{Stojkovic2023b,
  author    = {Stojkovic, Jovan and Xu, Tianyin and Franke, Hubertus and Torrellas, Josep},
  booktitle = {2023 IEEE International Symposium on High-Performance Computer Architecture (HPCA)},
  title     = {SpecFaaS: Accelerating Serverless Applications with Speculative Function Execution},
  year      = {2023},
  pages     = {814-827},
  doi       = {10.1109/HPCA56546.2023.10071120},
}

@InProceedings{Qi2022,
  author    = {Qi, Shixiong and Monis, Leslie and Zeng, Ziteng and Wang, Ian-chin and Ramakrishnan, K. K.},
  booktitle = {Proceedings of the ACM SIGCOMM 2022 Conference},
  title     = {SPRIGHT: Extracting the Server from Serverless Computing! High-Performance EBPF-Based Event-Driven, Shared-Memory Processing},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {780–794},
  publisher = {Association for Computing Machinery},
  series    = {SIGCOMM '22},
  abstract  = {Serverless computing promises an efficient, low-cost compute capability in cloud environments. However, existing solutions, epitomized by open-source platforms such as Knative, include heavyweight components that undermine this goal of serverless computing. Additionally, such serverless platforms lack dataplane optimizations to achieve efficient, high-performance function chains that facilitate the popular microservices development paradigm. Their use of unnecessarily complex and duplicate capabilities for building function chains severely degrades performance. 'Cold-start' latency is another deterrent.We describe SPRIGHT, a lightweight, high-performance, responsive serverless framework. SPRIGHT exploits shared memory processing and dramatically improves the scalability of the dataplane by avoiding unnecessary protocol processing and serialization-deserialization overheads. SPRIGHT extensively leverages event-driven processing with the extended Berkeley Packet Filter (eBPF). We creatively use eBPF's socket message mechanism to support shared memory processing, with overheads being strictly load-proportional. Compared to constantly-running, polling-based DPDK, SPRIGHT achieves the same dataplane performance with 10\texttimes{} less CPU usage under realistic workloads. Additionally, eBPF benefits SPRIGHT, by replacing heavyweight serverless components, allowing us to keep functions 'warm' with negligible penalty.Our preliminary experimental results show that SPRIGHT achieves an order of magnitude improvement in throughput and latency compared to Knative, while substantially reducing CPU usage, and obviates the need for 'cold-start'.},
  doi       = {10.1145/3544216.3544259},
  isbn      = {9781450394208},
  keywords  = {event-driven, serverless, eBPF, function chain},
  location  = {Amsterdam, Netherlands},
  numpages  = {15},
  url       = {https://doi.org/10.1145/3544216.3544259},
}

@InProceedings{Gu2022,
  author    = {Gu, Lin and Chen, Zirui and Xu, Honghao and Zeng, Deze and Li, Bo and Jin, Hai},
  booktitle = {IEEE INFOCOM 2022 - IEEE Conference on Computer Communications},
  title     = {Layer-aware Collaborative Microservice Deployment toward Maximal Edge Throughput},
  year      = {2022},
  pages     = {71-79},
  doi       = {10.1109/INFOCOM48880.2022.9796670},
}

@InProceedings{Poularakis2019,
  author    = {Poularakis, Konstantinos and Llorca, Jaime and Tulino, Antonia M. and Taylor, Ian and Tassiulas, Leandros},
  booktitle = {IEEE INFOCOM 2019 - IEEE Conference on Computer Communications},
  title     = {Joint Service Placement and Request Routing in Multi-cell Mobile Edge Computing Networks},
  year      = {2019},
  pages     = {10-18},
  doi       = {10.1109/INFOCOM.2019.8737385},
}

@InProceedings{Li2023a,
  author    = {Li, Yuepeng and Zeng, Deze and Gu, Lin and Ou, Mingwei and Chen, Quan},
  booktitle = {IEEE INFOCOM 2023 - IEEE Conference on Computer Communications},
  title     = {On Efficient Zygote Container Planning toward Fast Function Startup in Serverless Edge Cloud},
  year      = {2023},
  pages     = {1-9},
  doi       = {10.1109/INFOCOM53939.2023.10228916},
}

@InProceedings{Shang2023,
  author    = {Shang, Xiaojun and Mao, Yingling and Liu, Yu and Huang, Yaodong and Liu, Zhenhua and Yang, Yuanyuan},
  booktitle = {IEEE INFOCOM 2023 - IEEE Conference on Computer Communications},
  title     = {Online Container Scheduling for Data-intensive Applications in Serverless Edge Computing},
  year      = {2023},
  pages     = {1-10},
  doi       = {10.1109/INFOCOM53939.2023.10229034},
}

@InProceedings{Xu2023,
  author    = {Xu, Zichuan and Fu, Yuexin and Xia, Qiufen and Li, Hao},
  booktitle = {IEEE INFOCOM 2023 - IEEE Conference on Computer Communications},
  title     = {Enabling Age-Aware Big Data Analytics in Serverless Edge Clouds},
  year      = {2023},
  pages     = {1-10},
  doi       = {10.1109/INFOCOM53939.2023.10228905},
}

@InProceedings{Satapathy2023,
  author    = {Satapathy, Utkalika and Thakur, Rishabh and Chattopadhyay, Subhrendu and Chakraborty, Sandip},
  booktitle = {IEEE INFOCOM 2023 - IEEE Conference on Computer Communications},
  title     = {DisProTrack: Distributed Provenance Tracking over Serverless Applications},
  year      = {2023},
  pages     = {1-10},
  doi       = {10.1109/INFOCOM53939.2023.10228884},
}

@Misc{Serverle75:online,
  howpublished = {\url{https://aws.amazon.com/lambda/}},
  note         = {(Accessed on 09/06/2023)},
  title        = {Serverless Computing - AWS Lambda - Amazon Web Services},
  year         = {2023},
}

@Article{Liu2023,
  author     = {Liu, Xuanzhe and Wen, Jinfeng and Chen, Zhenpeng and Li, Ding and Chen, Junkai and Liu, Yi and Wang, Haoyu and Jin, Xin},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  title      = {FaaSLight: General Application-Level Cold-Start Latency Optimization for Function-as-a-Service in Serverless Computing},
  year       = {2023},
  issn       = {1049-331X},
  month      = {jul},
  number     = {5},
  volume     = {32},
  address    = {New York, NY, USA},
  articleno  = {119},
  doi        = {10.1145/3585007},
  issue_date = {September 2023},
  keywords   = {cold start, Serverless computing, optional function elimination, performance optimization},
  numpages   = {29},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3585007},
}

@InProceedings{10229090,
  author    = {Gu, Rong and Chen, Xiaofei and Dai, Haipeng and Wang, Shulin and Wang, Zhaokang and Tu, Yaofeng and Huang, Yihua and Chen, Guihai},
  booktitle = {IEEE INFOCOM 2023 - IEEE Conference on Computer Communications},
  title     = {Time and Cost-Efficient Cloud Data Transmission based on Serverless Computing Compression},
  year      = {2023},
  pages     = {1-10},
  doi       = {10.1109/INFOCOM53939.2023.10229090},
}

@InProceedings{Gu2023,
  author    = {Gu, Rong and Chen, Xiaofei and Dai, Haipeng and Wang, Shulin and Wang, Zhaokang and Tu, Yaofeng and Huang, Yihua and Chen, Guihai},
  booktitle = {IEEE INFOCOM 2023 - IEEE Conference on Computer Communications},
  title     = {Time and Cost-Efficient Cloud Data Transmission based on Serverless Computing Compression},
  year      = {2023},
  pages     = {1-10},
  doi       = {10.1109/INFOCOM53939.2023.10229090},
}

@Article{Shao2023,
  author  = {Shao, Xun and Hasegawa, Go and Dong, Mianxiong and Liu, Zhi and Masui, Hiroshi and Ji, Yusheng},
  journal = {IEEE Transactions on Services Computing},
  title   = {An Online Orchestration Mechanism for General-Purpose Edge Computing},
  year    = {2023},
  number  = {2},
  pages   = {927-940},
  volume  = {16},
  doi     = {10.1109/TSC.2022.3164149},
}

@Article{Xie2021,
  author  = {Xie, Renchao and Tang, Qinqin and Qiao, Shi and Zhu, Han and Yu, F. Richard and Huang, Tao},
  journal = {IEEE Wireless Communications},
  title   = {When Serverless Computing Meets Edge Computing: Architecture, Challenges, and Open Issues},
  year    = {2021},
  number  = {5},
  pages   = {126-133},
  volume  = {28},
  doi     = {10.1109/MWC.001.2000466},
}

@Article{Cicconetti2021,
  author  = {Cicconetti, Claudio and Conti, Marco and Passarella, Andrea},
  journal = {IEEE Transactions on Network and Service Management},
  title   = {A Decentralized Framework for Serverless Edge Computing in the Internet of Things},
  year    = {2021},
  number  = {2},
  pages   = {2166-2180},
  volume  = {18},
  doi     = {10.1109/TNSM.2020.3023305},
}

@Article{Deng2022,
  author  = {Deng, Shuiguang and Zhao, Hailiang and Xiang, Zhengzhe and Zhang, Cheng and Jiang, Rong and Li, Ying and Yin, Jianwei and Dustdar, Schahram and Zomaya, Albert Y.},
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  title   = {Dependent Function Embedding for Distributed Serverless Edge Computing},
  year    = {2022},
  number  = {10},
  pages   = {2346-2357},
  volume  = {33},
  doi     = {10.1109/TPDS.2021.3137380},
}

@InProceedings{Gu2021,
  author    = {Gu, Lin and Zeng, Deze and Hu, Jie and Li, Bo and Jin, Hai},
  booktitle = {IEEE INFOCOM 2021 - IEEE Conference on Computer Communications},
  title     = {Layer Aware Microservice Placement and Request Scheduling at the Edge},
  year      = {2021},
  pages     = {1-9},
  doi       = {10.1109/INFOCOM42981.2021.9488779},
}

@Article{Shukla2018,
  author  = {Shukla, Samta and Bhardwaj, Onkar and Abouzeid, Alhussein A. and Salonidis, Theodoros and He, Ting},
  journal = {IEEE Journal on Selected Areas in Communications},
  title   = {Proactive Retention-Aware Caching With Multi-Path Routing for Wireless Edge Networks},
  year    = {2018},
  number  = {6},
  pages   = {1286-1299},
  volume  = {36},
  doi     = {10.1109/JSAC.2018.2844999},
}

@InProceedings{Chen2023,
  author    = {Chen, Chen and Nagel, Lars and Cui, Lin and Tso, Fung Po},
  booktitle = {Proceedings of the 6th International Workshop on Edge Systems, Analytics and Networking},
  title     = {S-Cache: Function Caching for Serverless Edge Computing},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {1–6},
  publisher = {Association for Computing Machinery},
  series    = {EdgeSys '23},
  abstract  = {Serverless edge computing uses an event-driven model in which Internet-of-Things (IoT) services are run in short-lived, stateless containers only when invoked, leading to significant reduction of resource utilization. However, a cold-start of a container can take up to several seconds which significantly degrades the response time of serverless applications. Container caching can mitigate the cold-start problem at the cost of extra computing resources which violates the spirit of serverless computing. Therefore, we need to balance the cold-start overheads with the extra resource utilization for serverless edge computing. Nevertheless, the diverse ranges of containers lead to different cold-start overheads, resource consumption and invocation frequencies and these characteristics of containers are largely overlooked by existing caching policies. In this paper, we study the request distribution and caching problem for serverless edge computing. We devise an online request distribution algorithm with performance guarantee and present an adaptive caching policy which incorporates container frequency, container size and cold-start time. Via real-system implementation, the superiority of the proposed algorithm is verified by comparing with existing caching policies, including fixed caching and histogram based policies. Our results show that the proposed algorithm reduces both the average response time and cold-start frequency by a factor of 3 compared to current approaches.},
  doi       = {10.1145/3578354.3592865},
  isbn      = {9798400700828},
  keywords  = {serverless computing, function as a service, caching},
  location  = {Rome, Italy},
  numpages  = {6},
  url       = {https://doi.org/10.1145/3578354.3592865},
}

@InProceedings{Manco2017,
  author    = {Manco, Filipe and Lupu, Costin and Schmidt, Florian and Mendes, Jose and Kuenzer, Simon and Sati, Sumit and Yasukata, Kenichi and Raiciu, Costin and Huici, Felipe},
  booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles},
  title     = {My VM is Lighter (and Safer) than Your Container},
  year      = {2017},
  address   = {New York, NY, USA},
  pages     = {218–233},
  publisher = {Association for Computing Machinery},
  series    = {SOSP '17},
  abstract  = {Containers are in great demand because they are lightweight when compared to virtual machines. On the downside, containers offer weaker isolation than VMs, to the point where people run containers in virtual machines to achieve proper isolation. In this paper, we examine whether there is indeed a strict tradeoff between isolation (VMs) and efficiency (containers). We find that VMs can be as nimble as containers, as long as they are small and the toolstack is fast enough.We achieve lightweight VMs by using unikernels for specialized applications and with Tinyx, a tool that enables creating tailor-made, trimmed-down Linux virtual machines. By themselves, lightweight virtual machines are not enough to ensure good performance since the virtualization control plane (the toolstack) becomes the performance bottleneck. We present LightVM, a new virtualization solution based on Xen that is optimized to offer fast boot-times regardless of the number of active VMs. LightVM features a complete redesign of Xen's control plane, transforming its centralized operation to a distributed one where interactions with the hypervisor are reduced to a minimum. LightVM can boot a VM in 2.3ms, comparable to fork/exec on Linux (1ms), and two orders of magnitude faster than Docker. LightVM can pack thousands of LightVM guests on modest hardware with memory and CPU usage comparable to that of processes.},
  doi       = {10.1145/3132747.3132763},
  isbn      = {9781450350853},
  keywords  = {Xen, virtual machine, hypervisor, operating systems, Virtualization, unikernels, containers, specialization},
  location  = {Shanghai, China},
  numpages  = {16},
  url       = {https://doi.org/10.1145/3132747.3132763},
}

@Misc{Cherkasova1998,
  author    = {Ludmila Cherkasova},
  title     = {Improving www proxies performance with greedydual-size-frequency caching policy},
  year      = {1998},
  booktitle = {HP Labs Technical Report 98-69},
}

@Comment{jabref-meta: databaseType:bibtex;}
